<!DOCTYPE html>
<html lang="en">
  <head>
    <style>
      table {
        border-collapse: collapse;
        width: 55%; 
      }
      td,th {
        padding: 3px; /* Поля вокруг содержимого таблицы */
 border: 1px solid black /* Параметры рамки */
      }
    </style>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>HTML-junior.docx</title>
    <link rel="stylesheet" href="STYLE.CSS" />
    <body>
      <div>
      <h1 style="font-weight: 500; font-size: 35px;">Сравнение открытых OLAP-систем
        <br>Big Data: ClickHouse, Druid и Pinot</h1>
         <p>Оригинал - https://medium-com/asdasdasdasdasdasdasdasdas</p>
         <p><a href="/">ClickHouse, Druid и Pinot</a>-три открытых хранилища данных, которе позволяют<br>
          Выполнять аналитические запросы на больших объемах данных с интерактивными<br>
          задержками. Эта статья - перевод <a href="/">подробного сравнения</a>, выполненного Романом<br>
          Левентовым.
         </p>


      <h2 style="font-weight: 300;">Источники информации</h2>
  
         <p>Подробности реализации <strong>ClickHouse</strong> стали мне известны от <a href="/">Алексея Зателепина,</a><br>
         полного из <b>ключевых разработчиков проекта.</b> Доступная на английском<br>
         документация достаточно скудна - наилучшим источником информации служат<br>
         последние четыре секции <a href="/">данной страницы документации.</a></p>
  
         <p><b>Я сам участвую в развитии Druid</b>, но у меня нет личной заинтересованности в этой<br>
         системе - по правле говоря, скорее всего в ближайшее время я перестану заниматься<br>
         ее разработкой. Поэтому читатели могут рассчитывать на отсутствие какой-либо<br>
         предвзятости.</p>
         <p>Все, что я буду далее писать про <b>Pinot</b>, основывается на странице <a href="/">Архитектура в вики<br>
         Pinot</a>, а также на других страницах вики в разделе "Проектная документация".<br>
         Последний раз они обновлялись в июне 2017 года - больше, чем полгода назад.</p>
  
         <p>Рецензентами оригинальной статьи стали Алексей Зателепин и <a href="/"> Виталий Людвиченко</a><br>
         (разработчики ClickHouse), <a href="/">Жан Мерлино</a>(Самый активный разработчик Druid),<a href="/">Кишор<br>
          Гопалакришна</a>(архитектор Pinot) и <a href="/">Жан-Француа Им</a>(разработчик Pinot). Мы<br>
          присоединяемся к благодарности автора и полагаем, что это многократно повышает<br>
          авторитетность статьи.</p>
          <p><b>Предупреждение:</b> статья достаточно большая, поэтому вполне возможно вы захотите<br>
          ограничиться прочтением раздела "Заключение" в конце.</p>

      <h2 style="font-weight:500">Сходства между системами</h2> 
      <h3 style="font-weight:500">Связанные данные и вычисления</h3>
         <p><b>На фундаментальном уровне, ClickHouse, Druid и Pinot похожи,</b> поскольку они<br>
         хранят данные и выполняют обработку запросов на одних и тех же узлах, уходя от<br>“разъединенной” архитектуры BigQuery. Недавно я уже описывал несколько<br> 
         наследственных проблем со связанной архитектурой в случае Druid [<a href="/">1, 2</a>]. Открытого<br>
         эквивалента для BigQuery на данный момент не существует (за исключением, разве<br> что, <a href="/">Drill?</a>) Возможным подходам к построению подобных открытых систем посвящена<br>
         <a href="/">другая статье в моем блоге.</a></p>

      <h2 style="font-weight:500">Отличия от Big Data SQL-систем: индексы и статическое<br>
       распределение данных</h2>

         <p>Рассматриваемые в этой статье системы <b>выполняют запросы быстрее,</b> чем<br> 
         системы Big Data из семейства класса SQL-on-Hadoop: Hive, Impala, Presto и Spark,<br> 
        даже когда последние получают доступ к данным, хранящимся в колоночном формате<br>
         - к примеру, Parquet или Kudu. Это происходит потому, что в ClickHouse, Druid и Pinot:
           <ul>
             <li>Имеется <b>свой собственный формат для хранения данных с индексами,</b> и<br>
              они тесно интегрированы с движками обработки запросов. Системы класса<br> 
              SQL-on-Hadoop обычно можно назвать агностиками относительно форматов<br>
              данных и поэтому они менее “навязчивы” в бэкендах Big Data.</li>
       <br>
             <li><b>Данные распределены относительно “статично”</b> между узлами, и при<br>
             распределенном выполнении запроса это можно использовать. Обратная<br> 
             сторона медали при этом в том, что ClickHouse, Druid и Pinot <b>не поддерживают<br> 
            запросы, которые требуют перемещения большого количества данных</b><br>
             между узлами - к примеру, join между двумя большими таблицами.</li>
           </ul>
      <h2 style="font-weight:500">Отсутствие точечных обновлений и удалений</h2>
           <p>Находясь на другой стороне спектра баз данных, ClickHouse, Druid и Pinot <b>не<br> 
            поддерживают точечные обновления и удаления</b>, в противоположность<br>
            колоночным системам вроде Kudu, InfluxDB и Vertica (?). Это даёт ClickHouse, Druid и<br> 
            Pinot возможность производить более эффективное колоночное сжатие и более<br>
            агрессивные индексы, что означает <b>большую эффективность использования<br> 
            ресурсов</b> и быстрое выполнение запросов.</p>

           <p>Разработчики ClickHouse в Yandex планируют начать поддерживать <a href="/">обновления и<br>
            удаления в будущем,</a> но я не уверен, будут ли это “настоящие” точечные запросы или<br> 
            обновления/удаления диапазонов данных.</p>

      <h2 style="font-weight:500">Поглощение в стиле Big Data</h2>
            <p>Все три системы поддерживают потоковое поглощение данных из Kafka. Druid и Pinot<br>
            поддерживают потоковую передачу данных стриминг в <a href="/">Лямбда-стиле</a> и пакетное<br> поглощение одних и тех же данных. ClickHouse поддерживает пакетные вставки<br>
            напрямую, поэтому ему не требуется отдельная система пакетного поглощения<br>
            подобная той, что используется в Druid и Pinot. Если вас интересуют подробности, то<br>
            их вы сможете найти далее.</p>

     <h2 style="font-weight:500">Проверено на крупном масштабе</h2>
            <p>Все три системы проверены на работоспособность в крупных масштабах: в<br>
            <a href="/">Yandex.Metrica работает кластер ClickHouse,</a> состоящий из примерно десятка тысяч<br>
            ядер CPU. В Metamarkets используется <a href="/">кластер Druid аналогичного размера.</a> Один<br> 
            кластер Pinot в LinkedIn включает в себя <a href=“/">тысячи машин”.</a></p>

     <h2 style="font-weight:500">Незрелость</h2>

            <p>Все рассматриваемые в статье системы являются <b>незрелыми по меркам открытых<br> 
            enterprise-систем Big Data.</b> Однако, скорее всего они незрелы не более, чем<br> 
            среднестатистическая открытая система Big Data - но это совсем другая история. В<br>
            ClickHouse, Druid и Pinot недостает некоторых очевидных оптимизаций и<br> 
            функциональности, и они кишат багами (насчет ClickHouse и Pinot я не уверен на все<br>
            100%, но не вижу причин, по которым они в этом плане были бы лучше Druid).</p>
            <p>Это плавно подводит нас к следующему важному разделу.</p>

     <h1 style="font-size: 28px; font-weight: 500;">Про сравнение производительности и выбор<br> 
     системы</h1>

            <p>Я регулярно вижу в сети, как некоторые проводят сравнения систем больших данных:<br> 
            они берут набор своих данных, каким-либо образом “скармливают” его оцениваемой<br> 
            системе, а затем немедленно пытаются измерить производительность - сколько<br> 
            памяти или дискового пространства было занято, и насколько быстро выполнялись<br> 
            запросы. Причем понимание того, как устроены изнутри испытываемые ими системы, у<br>
            них отсутствует. Затем, используя лишь подобные специфичные данные о<br> 
            производительности - иногда вместе со списками функциональности, которая им<br> 
            нужна и которая есть в системе <em>на настоящий момент,</em> - они в итоге делают свой<br> 
            выбор или, что еще хуже, выбирают написать свою собственную, “лучшую” систему с<br> 
            нуля.</p>
            <p>Такой подход мне кажется неправильным, по крайней мере он неприменим в<br> 
            отношении открытых OLAP-систем для Big Data. Задача создания системы Bid Data<br> 
            OLAP, которая смогла бы работать эффективно в большинстве сценариев<br> 
            использования и содержала бы все необходимые функции настолько велика, что я<br> 
            оцениваю ее реализацию как минимум в <b>100 человеко-лет.</b></p>
            <p>На сегодня, ClickHouse, Druid и Pinot оптимизированы <em>только</em> для конкретных<br> 
            сценариев использования, которые требуются их разработчиком - и содержат по<br> 
            большей части лишь те функции, в которых нуждаются сами разработчики. Я могу<br> 
            гарантировать, что ваш случай обязательно “упрется” в те узкие места, с которыми<br> 
            разработчики рассматриваемых OLAP-систем еще не сталкивались - или же в те<br> 
            места, что их не интересуют. </p>
            <p>Не говоря уже о том, что упомянутый выше подход “забросить данные в систему, о<br> 
            которой вы ничего не знаете, и затем измерить её эффективность” весьма вероятно<br> 
            даст искаженный результат из-за серьезных “узких” мест, которые на самом деле<br> 
            могли бы быть исправлены <b>простым изменением конфигурации</b>, схемы данных или<br> 
            другим построением запроса.</p>

     <h2 style="font-weight:500">CloudFlare: ClickHouse против Druid</h2>

            <p>Одним таким примером, хорошо иллюстрирующим описанную выше проблему,<br> 
            является пост Марека Вавруша о <a href="/">выборе между ClickHouse и Druid в Cloudflare</a>. Им<br> 
            потребовалось 4 сервера ClickHouse (которые со временем превратились в 9), и по их<br> 
            оценкам, для разворачивания аналогичной установки Druid им бы потребовались<br> 
            “сотни узлов”. Пусть Марек и признает, что <b>сравнение является нечестным,</b><br>
            поскольку Druid недостаёт “сортировки по первичному ключу”, он возможно даже не<br> 
            осознает, что достичь примерно того же самого эффекта в Druid возможно просто<br> 
            <a href="/">установив правильный порядок измерений в “ingestion spec”</a> и произведя простую<br> 
            подготовку данных: обрезать значение колонки <font face="Courier New" size="3" >__time</font> в Druid до некоей грубой<br> 
            детализации (к примеру, один час) и опционально добавить другую “длинно-типовую”<br> 
            колонку “precise_time”, если для некоторых запросов требуются более точные<br> 
            временные рамки. Да, это хак, но, как мы только что выяснили, и в Druid можно<br> 
            сортировать данные по какому-либо измерению перед <font face="Courier New" size="3" >__time</font>_, и это достаточно<br> 
            просто реализовать.</p>
            <p>Впрочем, я не стану спорить с их итоговым решением выбрать ClickHouse, поскольку<br> 
            на масштабе примерно в 10 узлов и для их нужд ClickHouse мне тоже кажется лучшим<br> 
            выбором, чем Druid. Но сделанное ими заключение о том, что ClickHouse как минимум<br> 
            на порядок эффективнее (по меркам стоимости инфраструктуры), чем Druid - это<br> 
            серьезное заблуждение. На самом деле, из рассматриваемых нами сегодня систем,<br> 
            <b>Druid предлагает наилучшую возможность для реально дешевых установок</b><br> 
            (смотрите раздел “Уровни узлов обработки запросов в Druid ” ниже).</p>

               <ul>
                 <span style="background-color:yellow;">Когда вы выбираете систему OLAP Big Data, не сравнивайте то, насколько они<br> 
                 сейчас хорошо подходят для вашего случая. Сейчас они все субоптимальны.<br> 
                 Вместо этого, сравните, насколько быстро ваша компания способна заставить<br> 
                 двигаться эти системы в том направлении, которое нужно именно вам.</span>
               </ul>

             <p>В силу своей фундаментальной архитектурной схожести, ClickHouse, Druid и Pinot<br> 
             имеют примерно один и тот же “предел” эффективности и оптимизации<br> 
             производительности. Здесь нет “волшебной таблетки”, которая позволила бы какой-<br>
             либо из этих систем быть быстрее, чем остальные. Не позволяйте запутать себя тем<br> 
             фактом, что <em>в своем текущем состоянии</em> системы показывают себя очень по-разному<br> 
             в различных бенчмарках. </p>

            <p>Допустим, Druid не поддерживает “сортировку по первичному ключу” настолько<br> 
             хорошо, насколько это умеет ClickHouse - а ClickHouse в свою очередь не<br> 
             поддерживает “инвертированные индексы” столь же хорошо, как Druid, что дает<br> 
             данным системам преимущества с той или иной нагрузкой. <b>Упущенные оптимизации<br> 
             могут быть реализованы в выбранной системе при помощи не таких уж и<br> 
             больших усилий</b>, если у вас есть намерение и возможность решиться на подобный<br> 
             шаг.</p>

                <ul>
                  <li>В вашей организации должны быть инженеры, способные прочитать, понять и<br> 
                    модифицировать исходный код выбранной системы, к тому же у них должно<br> 
                    быть на это время. Заметьте, что ClickHouse написан на C++, а Druid и Pinot —<br> 
                    на Java.</li>
                    <br>
                  <li>Или же ваша организация должна подписать контракт с компанией, которая<br> 
                    оказывает поддержку выбранной системы. Это будут <a href="/">Altinity</a> для ClickHouse,<br> 
                    <a href="/">Imply</a> и <a href="/">Hortonworks</a> для Druid. Для Pinot таких компаний в данный момент нет.</li>
                </ul>
            <p>Другие сведения о разработке систем, которые вам стоит принять во внимание:</p>

                <ul>
                  <li>Авторы ClickHouse, работающие в Yandex, утверждают, что они тратят 50%<br> 
                    своего времени на создание функциональности, которая требуется им внутри<br> 
                    компании, и другие 50% уходят на функции, который набирают большинство<br> 
                    “голосов сообщества”. Однако, чтобы вы получили от этого факта<br> 
                    преимущество, требуется, чтобы <b>функции, которые нужны вам, были и<br> 
                    наиболее востребованы сообществом</b> ClickHouse.</li>
                  <li>Разработчики Druid из Imply мотивированы работать над широко<br> 
                    используемыми функциями, поскольку это позволит им максимально увеличить<br> 
                    объем охвата своего бизнеса в будущем.</li>
                  <li>Процесс разработки Druid сильно напоминает <a href="/"></a>модель Apache</a>, когда ПО<br> 
                    несколько лет разрабатывается несколькими компаниями, у каждой из который<br> 
                    достаточно своеобразные и различные приоритеты, и среди них нет ведущей<br> 
                    компании. ClickHouse и Pinot пока еще далеки от подобного этапа, поскольку<br> 
                    ими занимаются соответственно лишь Yandex и Linkedin. Сторонний вклад в<br> 
                    развитие Druid имеет минимальный шанс быть отклоненным в силу того, что он<br> 
                    расходится с видением основного разработчика - ведь <b>в Druid нет “основной”<br> 
                    компании-разработчика.</b></li>
                  <li>Druid поддерживает “API разработчика”, который позволяет привносить<br> 
                    собственные типы колонок, механизмы агрегации, возможные варианты для<br> 
                    «глубокого хранения» и пр., причем все это вы можете держать в кодовой базе,<br> 
                    отдельной от самого ядра Druid. Данное API документировано разработчиками<br> 
                    Druid, и они следят за его совместимостью с предыдущими версиями. Однако,<br> 
                    оно недостаточно “взрослое”, и ломается практически с каждым новым релизом<br> 
                    Druid. Насколько мне известно, в ClickHouse и Pinot схожие API не<br> 
                    поддерживаются.</li>
                  <li>Согласно Github, <b>над Pinot работает наибольшее число людей</b> - по всей<br> 
                    видимости, лишь за прошлый год в Pinot было вложено <a href="/"></a>не менее 10 человеко-<br>
                    лет</a>. Для ClickHouse эта цифра составляет примерно 6 человеко-лет, а для<br> 
                    Druid - 7. В теории, это должно означать, что Pinot улучшается быстрее всех<br> 
                    остальных систем, которые мы рассматриваем.</li>
                </ul>

            <p>Архитектуры Druid и Pinot почти что идентичны друг другу, в то время как ClickHouse<br> 
             стоит слегка в стороне. Поэтому сначала мы сравним ClickHouse c “обобщенной”<br> 
             архитектурой Druid/Pinot, а затем обсудим мелкие различия между Druid и Pinot.</p>

      <h2 style="font-weight:500">Различия между ClickHouse и Druid/Pinot</h2>

      <h3 style="font-weight:400; font-size: 20px;">Управление данным: Druid и Pinot</h3>
            <p>В Druid и Pinot, все данные в каждой “таблице” (как бы она не называлась в<br> 
              терминологии этих систем) разбиваются на указанное количество частей. По<br> 
              временой оси, данные обычно разделены с заданым интервалом. Затем эти части<br> 
              данных «запечатываются» индивидуально в самостоятельные автономные сущности,<br> 
              называемые «сегментами». Каждый сегмент включает в себя метаданные таблицы,<br> 
              сжатые столбчатые данные и индексы.</p>

            <p>Сегменты хранятся в файловой системе хранилища «глубокого хранения» (например,<br> 
              HDFS) и могут быть загружены на узлы обработки запросов, но последние не отвечают<br> 
              за устойчивость сегментов, поэтому узлы обработки запросов могут быть заменены<br> 
              относительно свободно. <b>Сегменты не привязаны жестко к конкретным узлам</b> и<br> 
              могут быть загружены на те или другие узлы. Специальный выделенный сервер<br> 
              (который называется “координатором” в Druid и “контроллером” в Pinot, но я ниже<br> 
              обращаюсь к нему как к “мастеру”) отвечает за присвоение сегментов узлам, и<br> 
              перемещению сегментов между узлами, если потребуется.</p>

            <p>Это не противоречит тому, что я отмечал выше, все три системы имеют статическое<br> 
              распределение данных между узлами, поскольку загрузки сегментов и их<br> 
              перемещения в Druid - и насколько я понимаю в Pinot - являются дорогими<br> 
              операциями и потому не выполняются для каждой отдельной очереди, а происходят<br> 
              обычно раз в несколько минут/часов/дней.</p>

            <p>Метаданные сегментов хранятся в ZooKeeper - напрямую в случае Druid, и при<br> 
              помощи фреймворка <a href="/"></a>Helix</a> в Pinot. В Druid метаданные также хранятся в базе SQL, об<br> 
              этом будет подробнее в разделе “Различия между Druid и Pinot”.</p>
      <h3 style="font-weight:500; font-size: 22px;">Управление данными: ClickHouse</h3> 
            <p>В ClickHouse нет “сегментов”, содержащих данные, попадающие в конкретные<br> 
              временные диапазоны. В нем нет “глубокого хранения” для данных, узлы в кластере<br> 
              ClickHouse также отвечают и за обработку запросов, и за постоянство/устойчивость<br> 
              данных, хранящихся на них. Так что вам <b>не потребуется HDFS</b> или облачное<br> 
              хранилище данных вроде Amazon S3.</p>
            <p>В ClickHouse имеются секционированные таблицы, состоящие из указанного набора<br> 
              узлов. Здесь нет “центральной власти” или сервера метаданных. Все узлы, между<br> 
              которыми разделена та или иная таблица, содержат полные, идентичные копии<br> 
              метаданных, включая адреса всех остальных узлов, на которых хранятся секции этой<br> 
              таблицы.</p>
            <p>Метаданные секционированной таблицы включают “весы” узлов для распределения<br> 
              свежезаписываемых данных - к примеру, 40% данных должны идти на узел A, 30% на<br> 
              узел B и 30% на C. Обычно же распределение должно происходить равномерно,<br> 
              “перекоос”, как в этом примере, требуется только тогда, когда к секционированной<br> 
              таблице добавляется новый узел и нужно побыстрее заполнить его какими-либо<br> 
              данными. <b>Обновления этих “весов” должны выполняться вручную</b><br> 
              администраторами кластера ClickHouse, или же автоматизированной системой,<br> 
              построенной поверх ClickHouse.</p>
      <h3 style="font-weight:500; font-size: 22px;">Управление данными:сравнение</h3>
            <p>Подход к управлению данными в ClickHouse проще, чем в Druid и Pinot: не требуется<br> 
              “глубокого хранилища”, всего один тип узлов, не требуется выделенного сервера для<br> 
              управления данными. Но подход ClickHouse приводит к некоторым трудностям, когда<br> 
              любая таблица данных вырастает настолько большой, что требуется ее разбиение<br> 
              между десятком или более узлов: коэффициент усиления запроса становится<br> 
              настолько же велик, насколько и фактор секционирования - даже для запросов,<br> 
              которые покрывают небольшой интервал данных:</p>
              <div>
              <img src="1.jpg" alt="/">
              <figcaption style="padding:0px 120px;"><em>Компромисс распределения данных в ClickHouse</em></figcaption>
              </div>
            <p>В примере, показанном на изображении выше, данные таблицы распределены между<br> 
              тремя узлами в Druid/Pinot, но запрос по малому интервалу данных обычно<br> 
              затрагивает лишь два из них (до той поры, пока интервал не пересечет пограничный<br> 
              интервал сегмента). В ClickHouse, любые запросы будут вынуждены затронуть три<br> 
              узла – если таблица сегментирована между тремя узлами. В данном примере разница<br> 
              не выглядит настолько существенно, однако представьте себе, что случится, если<br> 
              число узлов достигнет 100 – в то время как фактор сегментирования по-прежнему<br> 
              может быть равен, например, 10 в Druid/Pinot.</p>
            <p>Чтобы смягчить эту проблему, самый большой кластер ClickHouse в Яндексе,<br> 
              состоящий из сотен узлов, в действительности разбит на многие «под-кластеры» с<br> 
              несколькими десятками узлов в каждом. Кластер ClickHouse используется в работе с<br> 
              аналитикой по веб-сайтам, и каждая точка данных имеет измерение «ID вебсайта».<br> 
              Существует жесткая привязка каждого ID сайта к конкретному под-кластеру, куда идут<br> 
              все данные для этого идентификатора сайта. Поверх кластера ClickHouse есть слой<br> 
              бизнес-логики, который управляет этим разделением данных<br> 
              при поглощении данных и выполнении запросов. К счастью, в их сценариях использования совсем немного<br> 
              запросов затрагивают несколько идентификаторов сайтов, и подобные запросы идут<br> 
              не от пользователей сервиса, поэтому у них нет жесткой привязки к реальному<br> 
              времени согласно соглашению об уровне услуг.</p>
            <p>Другим недостатком подхода ClickHouse является то, что, когда кластер растет очень<br> 
              быстро, данные не могут перебалансироваться автоматически без участия человека,<br> 
              который вручную поменяет «веса» узлов в разбиваемой таблице.</p>
              <br>
              
      <h3 style="font-weight:500; font-size: 22px;">Уровни узлов обработки запросов в Druid</h3>
            <p>Управление данными при помощи сегментов «проще себе представить» - эта<br> 
              концепция хорошо ложится на наши когнитивные способности. Сами сегменты можно<br> 
              перемещать между узлами относительно просто. Эта две причины позволили Druid<br> 
              реализовать “разделение на уровни” узлов, занимающихся обработкой запросов:<br> 
              старые данные автоматически перемещаются на сервера с относительно большими<br> 
              дисками, но меньшим количеством памяти и CPU, что позволяет <b>значительно<br> 
              снизить стоимость большого рабочего кластера Druid</b> за счет замедления<br> 
              запросов к более старым данным.
              <br>
              <br>
              Эта функция позволяет Metamarkets экономить сотни тысяч долларов расходов на<br> 
              инфраструктуру Druid каждый месяц - в противовес тому варианту, если бы<br> 
              использовался “плоский” кластер.
              </p>
            <img src="2.jpg" alt="./">
            <figcaption style="padding: 0px 20px;"><em>Уровни узлов обработки запросов в Druid</em></figcaption>
           <p>Насколько мне известно, в ClickHouse и Pinot пока еще нет похожей функциональности<br> 
            - предполагается, что все узлы в их кластерах одинаковы.
            <br>
            <br>
            В силу того, что архитектура Pinot весьма схожа с архитектурой Druid, как мне кажется,<br> 
            будет не слишком сложно добавить аналогичную функцию в Pinot. Тяжелее будет в<br> 
            случае с ClickHouse, поскольку для реализации данной функции крайне полезно<br> 
            использование концепта “сегментов”, однако это всё равно возможно.
            </p>

      <h3 style="font-weight:500; font-size: 23px;">Репликация данных: Druid и Pinot</h3>
           <p>Единицей репликации в Druid и Pinot является единичный сегмент. Сегменты<br> 
            реплицируются на уровне «глубокого хранения» (например, в три реплики на HDFS,<br> 
            или при помощи хранилища BLOB-объектов в Amazon S3), и на уровне обработки<br> 
            запросов: обычно и в Druid и в Pinot, каждый сегмент загружается на два различных<br> 
            узла. «Мастер»-сервер мониторит уровни репликации для каждого сегмента и<br> 
            загружает сегмент на какой-либо сервер, если фактор репликации падает ниже<br> 
            заданного уровня (например, если какой-либо из узлов перестаёт отвечать).</p>
      <h3 style="font-weight:500; font-size: 23px;">Репликация данных: ClickHouse</h3>
           <p>Единицей репликации в ClickHouse является секция таблицы на сервере (например,<br> 
            все данные из какой-либо таблицы, хранящиеся на сервере). Аналогично<br> 
            секционированию, репликация в ClickHouse является скорее «статической и<br> 
            конкретной», чем «в облачном стиле»: несколько серверов знают, что они являются<br> 
            репликами друг друга (для некоторой конкретной таблицы; в случае другой таблицы,<br> 
            конфигурация репликации может отличаться). Репликация предоставляет и<br> 
            устойчивость, и доступность запросов. Когда повреждается диск на одном узле,<br> 
            данные не теряются, поскольку они хранятся еще и на другом узле. Когда какой-либо<br> 
            узел временно недоступен, запросы могут быть перенаправлены на реплику.
            <br>
            <br>
            В самом большом кластере ClickHouse в Яндексе есть два одинаковых набора узлов в<br> 
            различных дата-центрах, и они спарены. В каждой паре узлы являются репликами<br> 
            друг друга (используется фактор репликации, равный двум), и они расположены в<br> 
            различных дата-центрах.
            <br>
            <br>
            ClickHouse полагается на ZooKeeper для управления репликацией – поэтому, если вам<br> 
            не нужна репликация, то вам не нужен и ZooKeeper. Это означает, что ZooKeeper не<br> 
            потребуется и для ClickHouse, развернутого на одиночном узле.
            </p>
      <h3 style="font-weight:500; font-size: 23px;">Поглощение данных: Druid и Pinot</h3> 
           <p>В Druid и Pinot узлы обработки запросов специализируются на загрузке сегментов и<br> 
            обслуживают запросы к данным в сегментах; они не занимаются накоплением новых<br> 
            данных и производством новых сегментов.
            <br>
            <br>
            Когда таблица может обновляться с задержкой в час или более, сегменты создаются<br> 
            при помощи движков пакетной обработки – к примеру, Hadoop или Spark. И в<br> 
            Druid, и в Pinot есть первоклассная поддержка Hadoop из коробки. Существует <a href="/">сторонний плагин<br> 
            для поддержки индексации Druid в SparkБ</a>, но в данный момент официально он не<br> 
            поддерживается. Насколько мне известно, в Pinot такого уровня поддержки Spark пока<br> 
            нет, то есть вы должны быть готовы разобраться с интерфейсами Pinot и кодом, а<br> 
            затем самостоятельно написать код на Java/Scala, пусть это и не должно быть<br> 
            слишком сложно. (Впрочем, с момента публикации оригинальной статьи поддержка<br> 
            Spark в Pinot <a href="/">была внесена контрибьютором</a>).
            <br>
            <br>
            Когда таблица должна обновляться в реальном времени, здесь приходит на помощь<br> 
            идея “реалтаймовых» узлов, которые делают три вещи: принимает новые данные из<br> 
            Kafka (Druid поддерживает и другие источники), обслуживает запросы с недавними<br> 
            данными, создает сегменты в фоне и затем записывает их в “глубокое хранилище”.
            </p>
      <h3 style="font-weight:500; font-size: 23px;">Поглощение данных: ClickHouse</h3> 
           <p>Тот факт, что ClickHouse не требуется готовить “сегменты”, содержащие все данные и<br> 
            попадающие в заданные временные интервалы, позволяет строить более простую<br> 
            архитектуру поглощения данных. ClickHouse не требуется ни пакетный движок<br> 
            обработки вроде Hadoop, ни “реалтаймовые” узлы. Обычные узлы ClickHouse - те же<br> 
            самые, что занимаются хранением данных и обслуживают запросы к ним - напрямую<br> 
            принимают пакетные записи данных.
            <br>
            <br>
            Если таблица разбита на сегменты, то узел, который принимает пакетную запись<br> 
            (например, 10к строк) распределяет данные согласно “весам” (смотрите раздел ниже).<br> 
            Строки записываются одним пакетом, который формирует небольшое “множество”.<br> 
            Множество немедленно конвертируется в колоночный формат. На каждом узле<br> 
            ClickHouse работает фоновый процесс, который объединяет наборы строк в еще<br> 
            большие наборы. Документация ClickHouse сильно завязана на принцип, известный<br> 
            как “MergeTree”, и подчеркивает схожесть его работы с <a href="/">LSM-деревом</a>, хотя меня это<br> 
            слегка смущает, поскольку данные не организованы в деревья - они лежат в плоском<br> 
            колончатом формате.
            </p>
      <h3 style="font-weight:500; font-size: 23px;">Поглощение данных: сравнение</h3> 
           <p>Поглощение данных в Druid и Pinot является “тяжелым”: оно состоит из нескольких<br> 
            различных сервисов, и управление ими - это тяжелый труд.
            <br>
            <br>
            Поглощение данных в ClickHouse гораздо проще (что компенсируется сложностью<br> 
            управления “историческими” данными - т.е. данными не в реальном времени), но и<br> 
            здесь есть один момент: вы должны иметь возможность собирать данные в пакеты до<br> 
            самого ClickHouse. Автоматическое поглощение и пакетный сбор данных из <a href="/">Kafka<br> 
            доступно “из коробки”</a>, но если у вас используется другой источник данных в реальном<br> 
            времени (здесь подразумевается всё, что угодно, в диапазоне между инфраструктурой<br> 
            запросов, альтернативной Kafka, и стриминговых движков обработки, вплоть до<br> 
            различных HTTP-endpoint), то вам придется создать промежуточный сервис по сбору<br> 
            пакетов, или же внести код напрямую в ClickHouse.
            </p>

      <h3 style="font-weight:500; font-size: 23px;">Выполнение запроса</h3> 
           <p>В <b>Druid и Pinot</b> имеется отдельный слой узлов, называемых <em>“брокерами”</em>, которые<br> 
            принимают все запросы к системе. Они определяют, к каким “историческим”<br> 
            (<em>содержащим данные не в реальном времени</em>) узлам обработки запросов должны быть<br> 
            отправлены подзапросы, основываясь на отображении сегментов в узлы, в которых<br> 
            сегменты загружаются. Брокеры хранят информацию об отображении в памяти.<br> 
            Брокер-узлы отправляют дальше подзапросы к узлам обработки запросов, и когда<br> 
            результаты этих подзапросов возвращаются, брокер объединяет их и возвращает<br> 
            финальный комбинированный результат пользователю.<br>
            <br>
            Я не берусь предполагать, зачем при проектировании Druid и Pinot было принято<br> 
            решение о введении еще одного типа узлов. Однако, теперь они кажутся их<br> 
            неотъемлемой частью, поскольку, когда общее количество сегментов в кластере<br> 
            начинает превышать десять миллионов, информация об отображении сегментов в<br> 
            узлы начинает занимать гигабайты памяти. Это очень расточительно – выделять<br> 
            столько много памяти на каждом узле для обработки запросов. Вот вам и еще один<br> 
            недостаток, который накладывается на Druid и Pinot их «сегментированной»<br> 
            архитектурой управления данными.<br><br>
            В <b>ClickHouse</b> выделять отдельный набор узлов под “брокер запросов” обычно не<br> 
            требуется. Существует специальный, эфемерный <a href="/">“распределенный” тип таблицы</a> в<br> 
            ClickHouse, который может быть установлен на любом узле, и запросы к этой таблице<br> 
            будут делать все то же, за что отвечают брокер-узлы в Druid и Pinot. Обычно подобные<br> 
            эфемерные таблицы размещаются на каждом узле, который участвует в<br> 
            секционированной таблице, так что на практике каждый узел может быть “входной<br> 
            точкой” для запроса в кластер ClickHouse. Этот узел может выпускать необходимые<br> 
            подзапросы к другим секциями, обрабатывать свою часть запроса самостоятельно и<br> 
            затем объединять её с частичными результатами от других секций.<br><br>
            Когда узел (или один из процессинговых узлов в ClickHouse, или брокер-узел в Druid и<br> 
            Pinot) выпускает подзапросы к другим, и один или несколько подзапросов по какой-<br>
            либо причине заканчиваются неудачей, ClickHouse и Pinot обрабатывают эту ситуацию<br> 
            правильно: они объединяют результаты успешно выполненных подзапросов вместе, и<br> 
            всё равно возвращают частичный результат пользователю. <a href="/">Druid этой функции сейчас<br> 
            очень недостает:</a> если в нем выполнение подзапроса заканчивается неудачей, то<br> 
            неудачей закончится и весь запрос целиком.
            </p>
      <h3 style="font-weight:500; font-size: 22px;">ClickHouse vs. Druid или Pinot: Выводы</h3> 
           <p>“Сегментированный” подход к управлению данными в Druid и Pinot против более<br> 
            простого управления данными в ClickHouse определяет многие аспекты систем.<br> 
            Однако, важно заметить, что это различие оказывает небольшое (или не оказывает<br> 
            вовсе) влияние на потенциальную эффективность сжатия (впрочем, история про<br> 
            компрессию для всех трех систем имеет печальный конец по нынешнему состоянию<br> 
            дел), или на скорость обработки запросов.<br><br>
            <b>ClickHouse</b> похож на традиционные RDMBS, например, PostgreSQL. В частности,<br> 
            ClickHouse можно развернуть на всего один сервер. Если планируемый размер<br> 
            невелик - скажем, не больше порядка 100 ядер CPU для обработки запросов и 1 TB<br> 
            данных, я бы сказал, что ClickHouse имеет значительные преимущества перед Druid и<br> 
            Pinot в силу своей простоты и отсутствия необходимости в дополнительных типах<br> 
            узлов, таких как “мастер”, “узлы поглощения в реальном времени”, “брокеры”. На этом<br> 
            поле, ClickHouse соревнуется скорее с InfluxDB, чем с Druid или Pinot.<br><br>
            <b>Druid and Pinot</b> похож на системы Big Data вроде HBase. Здесь в виду имеются не<br> 
            характеристики производительности, а зависимость от ZooKeper, зависимость от<br> 
            персистентного реплицируемого хранилища (к примеру, HDFS), сосредоточение<br> 
            внимания на устойчивости к отказам отдельных узлов, а также автономная работа и<br> 
            управление данными, не требующими постоянного внимания человека.<br><br>
            Для широкого спектра приложений, ни ClickHouse, ни Druid или Pinot не являются<br> 
            очевидными победителями. В первую очередь, вы должны принимать во внимание<br> 
            вашу способность разобраться с исходным кодом системы, исправлять баги,<br> 
            добавлять новые функции и т.д. Это подробнее обсуждается в разделе “Про<br> 
            сравнение производительности и выбор системы”.<br><br>
            Во-вторых, вам стоит взглянуть на таблицу ниже. Каждая ячейка в этой таблице<br> 
            описывает свойство приложения, которое позволит определить предпочтительную<br> 
            систему. Строки отсортированы не в порядке важности. Важность различных свойств<br> 
            может разниться от приложения к приложению, но в целом можно применить<br> 
            следующий подход: если ваше приложение соответствует подавляющему<br> 
            большинству строк со свойствами в одной из колонок, то относящаяся к ней система в<br> 
            вашем случае является предпочтительным выбором.</p>
        <table   >
          <tr>
            <th>ClickHouse</th>
            <th>Druid или Pinot</th>
          </tr>
          <tr>
            <td>Малый кластер</td>
            <td>Большой кластер</td>
          </tr>
          <tr>
            <td>Немного таблиц</td>
            <td>Немного таблиц	Много таблиц</td>
          </tr>
          <tr>
            <td>Один набор данных</td>
            <td>Несколько несвязанных наборов данных</td>
          </tr>
          <tr>
            <td>Таблицы и данные находятся в кластере перманентно</td>
            <td>Таблицы и наборы данных периодически появляются в кластере и удаляются из него</td>
          </tr>
          <tr>
            <td>Размер таблиц (и интенсивность запросов к ним) остается стабильным во времени</td>
            <td>Таблицы значительно растут и сжимаются</td>
          </tr>
          <tr>
            <td>Однородные запросы (их тип, размер, распределение по времени суток и т.д.)</td>
            <td>Разнородные запросы</td>
          </tr>
          <tr>
            <td>В данных есть измерение, по которому оно может быть сегментировано, и почти не выполняется запросов, которые затрагивают данные, расположенные в нескольких сегментах</td>
            <td>Подобного измерения нет, и запросы часто затрагивают данные, расположенные </td>
          </tr>
          <tr>
            <td>Облако не используется, кластер должен быть развернут на специфическую конфигурацию физических серверов</td>
            <td>Кластер развернут в облаке</td>
            </tr>
          <tr>
            <td>Нет существующих кластеров Hadoop или Spark</td>
            <td>Кластеры Hadoop или Spark уже существуют и могут быть использованы</td>
          </tr>
        </table>
           <p><b>Примечание:</b> ни одно из свойств выше не означает, что вы должны использовать<br> 
            соответствующую систему (системы), или избегать другую. К примеру, если<br> 
            планируется, что ваш кластер будет большим, это не значит, что вы обязательно<br> 
            должны рассматривать только Druid или Pinot, исключив ClickHouse. Скорее всего, в<br> 
            данной ситуации Druid или Pinot могут быть лучшим выбором, но другие полезные<br> 
            свойства могут перевесить чашу весов в сторону ClickHouse, который для некоторых<br> 
            приложений является оптимальным выбором даже для больших кластеров.</p>
      <h2 style="font-weight:500; font-size: 28px;">Различия между Druid и Pinot</h2>
           <p>Как уже не раз отмечалось в данной статье, Druid и Pinot имеют весьма похожие<br> 
           архитектуры. Есть несколько достаточно заметных особенностей, которые есть в<br> 
           одной системе и отсутствуют в другой, и областей, в которых каждая из систем<br> 
           развита гораздо сильнее другой. Тем не менее, всё, о чем я собираюсь упомянуть<br> 
           ниже, можно воспроизвести в другой системе, приложив разумное количество усилий.<br><br>
           Между Druid и Pinot существует лишь <b>одно существенное различие</b>, которое<br> 
           слишком велико для того, чтобы от него избавились в обозримом будущем - это<br> 
           <b>реализация управления сегментами</b> в мастер-ноде. Кстати, разработчики обеих<br> 
           систем наверняка не хотели бы этого делать в любом случае, поскольку оба подхода<br> 
           имеют свои “за” и “против” - среди них нет такого, который был бы лучше.
           </p>
      <h2 style="font-weight:500; font-size: 23px;">Управление сегментами в Druid</h2>
      
           <p>Мастер-нода в Druid (и ни один из узлов в Pinot) не отвечают за сохранность<br> 
            метаданных в сегментах данных в кластере, и текущее отображение между<br> 
            сегментами и узлами обработки данных, на которых загружены сегменты. Эта<br> 
            информация хранится в ZooKeeper. Однако, Druid в дополнение хранит эту<br> 
            информацию еще и в SQL базе данных, которая необходима для развертывания<br> 
            кластера Druid. Не могу сказать, с какой целью было принято такое решение, но<br> 
            сейчас оно дает следующие преимущества:

            <ul>
              <li>В ZooKeeper <b>хранится меньше данных</b>. Только минимум информации об<br> 
                отображении идентификатора сегмента на список узлов, занимающихся<br> 
                обработкой запросов, куда загружен сегмент, сохраняется в ZooKeeper.<br> 
                Оставшиеся метаданные, к примеру, размер сегмента, список измерений и<br> 
                метрики, и т.д. - хранятся только в SQL базе данных.</li>
                <br>
              <li>Когда сегменты данных вытесняются из кластера, поскольку они становятся<br> 
                слишком старыми (это общая функция всех баз данных временных рядов - она<br> 
                есть и в ClickHouse, и в Druid, и в Pinot), они выгружаются из узлов обработки<br> 
                запросов и их метаданные удаляются из ZooKeeper, но не из “глубокого<br> 
                хранилища” и не из базы данных SQL. Пока они не будут удалены из этих мест<br> 
                вручную, <b>остается возможность “оживить” действительно старые данные<br> 
                быстро,</b> если он потребуются для построения отчетов или исследований.</li>
                <br>
              <li>Вряд ли это планировалось с самого начала, но теперь есть планы сделать<br> 
                <b>зависимость Druid от ZooKeeper опциональной.</b> Сейчас ZooKeeper<br> 
                используется для трех различных функций: управления сегментами,<br> 
                обнаружения сервисов и хранения свойств (например, для управления<br> 
                поглощением данных в реальном времени). Обнаружение сервисов может <a href="/">быть<br> 
                предоставлено Consul.</a> Управление сегментами может быть реализовано <a href="/">при<br> 
                помощи HTTP-команд,</a> и оно доступно нам благодаря тому, что функции<br> 
                хранения в ZooKeeper “бекапится” в базе SQL.</li>
            </ul>

            <p>То что нам приходится иметь в зависимостях базу данных SQL, приводит к большей<br> 
             нагрузке на эксплуатацию, особенно, если в компании еще не использовалась какая-<br>
             либо БД SQL. Druid поддерживает MySQL и PostgreSQL, есть и расширение для<br> 
             Microsoft SQL Server. Кроме того, когда Druid рразворачивается в облаке, можно<br> 
             использовать стандартные сервисы для управления RDBMS - к примеру, Amazon RDS.</p>
      <h2 style="font-weight:500; font-size: 23px;">Управление сегментами в Pinot</h2>
            <p>В отличие от Druid, который реализует всю логику управления сегментами<br> 
              самостоятельно и полагается только на <a href="/">Curator</a> для взаимодействия с ZooKeeper, Pinot<br> 
              делегирует большую часть логики управления сегментами и кластерами на <a href="/">фреймворк Helix.</a><br><br>
              С одной стороны, я могу понять, что это дает разработчикам Pinot возможность<br> 
              сосредоточиться на других частях их системы. В Helix возможно меньше багов, чем<br> 
              в логике внутри самого Druid, поскольку он тестируется в других условиях и поскольку в<br> 
              него, предположительно, было вложено гораздо больше рабочего времени.<br><br>
              С другой стороны, Helix возможно ограничивает Pinot своими “рамками фреймворка”.<br> 
              Helix, и следовательно, <b>Pinot, скорее всего будут зависеть от ZooKeeper всегда.</b><br><br>
              Далее я собираюсь перечислить менее важные различия между Druid и Pinot - в том<br> 
              смысле, что если у вас возникнет серьезное желание повторить одну из этих функций<br> 
              в вашей системе, то это будет вполне осуществимо.</p>
      <h2 style="font-weight:500; font-size: 23px;">«Проталкивание предикатов» в Pinot</h2>
            <p>Если во время поглощения данные секционируются в Kafka по каким-либо ключам<br> 
              измерений, Pinot создает сегменты, которые содержат информацию об этом<br> 
              разбиении и затем, когда выполняется запрос с предикатом на данном измерении,<br> 
              брокер-узел фильтрует сегменты таким образом, чтобы как можно меньше сегментов<br> 
              и узлов обработки запросов было затронуто.<br><br>
              Эта концепция в оригинале называется <b>“predicate pushdown”</b> и важна для<br> 
              поддержания высокой производительности в некоторых приложениях.<br><br>
              На данный момент Druid поддерживает разбиение по ключам, если сегменты были<br> 
              созданы в Hadoop, но еще не поддерживает сегменты, созданные во время<br> 
              поглощения в реальном времени. Druid сейчас не реализует функцию «проталкивания<br> 
              предикатов» на брокеры.</p>
      <h2 style="font-weight:500; font-size: 23px;">“Сменный” Druid и своевольный Pinot</h2>
             <p>Поскольку Druid используют различные организации и в его разработке принимают<br> 
              участие несколько компаний, он обзавелся поддержкой нескольких взаимозаменяемых<br> 
              опций для практически любой выделенной части или “сервиса”:</p>

              <ul>
                <li>HDFS, Cassandra, Amazon S3, Google Cloud Storage или Azure Blob Storage<br> 
                  и т.д. в качестве “глубокого хранилища”;</li>
                <li>Kafka, илиr RabbitMQ, Samza, или Flink, или Spark, Storm, и т.д. (через<br> 
                  <a href="/">Tranquility</a>) в качестве источника поглощения данных в реальном времени;</li>
                <li>Сам Druid, или Graphite, или Ambari, или StatsD, или Kafka в качестве “слива”<br> 
                  для телеметрии кластера Druid (метрик).</li>
              </ul>
              <p>В то же время Pinot почти целиком разрабатывался исключительно в стенах LinkedIn и<br> 
              должен был удовлетворять текущим нуждам компании, поэтому выбор, который вам<br> 
              предлагается, не так велик. В качестве “глубокого хранилища” необходимо<br> 
              использовать HDFS или Amazon S3, а для поглощения данных в реальном времени<br> 
              подойдет только Kafka. Но если кому-то это действительно понадобится, мне кажется,<br> 
              не составит особой сложности добавить поддержку любого другого сервиса в Pinot. К<br> 
              тому же, можно ожидать позитивных сдвигов в этом направлении, поскольку <a href="/">Uber</a> и<br> 
              Slack начинают использовать Pinot.
              <br>
      <h2 style="font-weight:500; font-size: 23px;">Формат данных и движок выполнения запросов лучше<br> 
        оптимизированы в Pinot</h2>
              <p>В частности, следующие функции <a href="/">формата сегментов Pinot</a> сейчас отсутствуют в<br> 
              Druid:</p>
              <ul>
                <li><b>Сжатие проиндексированных столбцов</b> с битовой гранулярностью, но<br> 
                  байтовой гранулярностью в Druid.</li>
                <li><b>Инвертированный индекс опционален </b> для каждого столбца. В Druid он<br> 
                  является обязательным, иногда этого не требуется, но все равно занимает<br> 
                  много места. Различие в потреблении места между Druid и Pinot, <a href="/">на которое<br> 
                  указывает Uber в своих тестах </a>, вполне возможно вызвано именно этимс<br></li>
                <li><b>Минимальные и максимальные значения </b> в числовых столбцах<br> 
                  записываются посегментно.</li>
                <li><b>поддержка сортировки данных из коробки.</b> В Druid этого можно достичь<br> 
                  только вручную и слегка специфическим способом (как было описано в разделе<br> 
                  “CloudFlare: ClickHouse против Druid”). Сортировка данных означает лучшее<br> 
                  сжатие, и эта функция в Pinot - еще одна причина различия между Druid и Pinot<br> 
                  в потреблении пространства (и производительности запросов!), на которую<br> 
                  указывает Uber.</li>
                <li><b>Формат даных</b>, используемый для многозначных столбцов, на данный<br> 
                  момент лучше оптимизирован в Pinot, чем в Druid.</li>
              </ul>
              <p>Однако, все это можно реализовать и в Druid. И несмотря на то, что формат Pinot<br> 
                оптимизирован существенно лучше, чем формат Druid, он все равно достаточно далек<br> 
                от того, чтобы быть оптимальным. Один из примеров: Pinot (как и Druid) использует<br> 
                только сжатие общего назначение (как Zstd) и еще не реализовали идеи сжатия из<br> 
                <a href="/">Gorilla.</a><br><br>
                К сожалению Uber по большей части использовал запросы <font face="Courier New" size="2" > count </font> (*) для сравнения<br> 
                производительности Druid и Pinot относительно выполнения запроса [<a href="/"> 1, 2</a>], который<br> 
                сейчас в Druid представляет собой тупое линейное сканирование, хотя его и несложно<br> 
                заменить <a href="/">корректной O(1) реализацией</a>. Это вам еще один пример бессмысленных<br> 
                сравнений в стиле “черного ящика”, о которых мы говорили ранее.<br><br>
                По моему мнению, причины сильного различия в производительности запросов <font face="Courier New" size="2">GROUP<br> 
                BY</font>, которое наблюдали в Uber, стоит искать в недостатке сортировки данных в<br> 
                сегментах Druid, как уже было отмечено выше в этом разделе.</p>
      <h2 style="font-weight:500; font-size: 23px;">У Druid есть более умный алгоритм присваивания<br> 
        (балансировки) сегментов</h2>
              <p>Алгоритм Pinot заключается в присвоении сегмента к узлам обработки запроса,<br> 
                которые имеют наименьшее число сегментов, загруженных в текущий момент.<br> 
                Алгоритм Druid является гораздо более сложным; он учитывает таблицу каждого<br> 
                сегмента и время, и применяет <b>сложную формулу для вычисления финального<br> 
                коэффициента</b>, согласно которому будут ранжированы узлы обработки запросов для<br> 
                выбора наилучшего, которому и будет присвоен новый сегмент. Этот алгоритм<br> 
                показал ускорение в скорости выполнения запросов в продакшне Metamarkets на <b>30-<br>
                40%.</b> Хотя, даже несмотря на подобный результат, мы им по-прежнему не слишком<br> 
                довольны - подробности можно прочитать <a href="/">в отдельной статье.</a><br><br>
                Не знаю, как в LinkedIn управляются со всем при помощи настолько простого<br> 
                алгоритма балансировки сегментов в Pinot, но, вполне возможно, их ожидают<br> 
                значительные улучшения по части производительности, если они решатся потратить<br> 
                время на совершенствование используемого ими алгоритма.</p>
      <h2 style="font-weight:500; font-size: 23px;">Pinot более устойчив к отказам при выполнении сложных<br> 
        запросов</h2>
              <p>Как уже упоминалось выше в разделе “Выполнение запроса”, когда брокер-узел<br> 
                создает подзапросы к другим узлам, некоторые подзапросы заканчиваются ошибкой,<br> 
                но Pinot объединяет результаты всех удачно выполненных подзапросов и по-<br>
                прежнему возвращает частичный результат пользователю.<br><br>
                В Druid такой функции на данный момент.</p>
      <h2 style="font-weight:500; font-size: 23px;">Иерархия узлов обработки запросов в Druid</h2>
              <p>Смотрите аналогичный раздел выше. Druid позволяет вводить уровни узлов обработки<br> 
                запросов для старых и новых данных, и для узлов со “старыми” данными соотношениеM<br> 
                “ресурсы CPU, RAM / число загруженных сегментов” гораздо ниже, что позволяет<br> 
                выиграть на расходах на инфраструктуру в обмен на низкую производительность<br> 
                запросов при доступе к старым данным.<br><br>
                Насколько мне известно, в Pinot на данный момент аналогичная функциональность<br> 
                отсутствует.</p>
      <h1 style="font-weight:500; font-size: 23px;">Заключение</h1>
               <p><b>ClickHouse, Druid и Pinot имеют фундаментально схожую архитектуру,</b> и<br> 
                занимают свою собственную нишу между Big Data-фреймворками общего назначения<br> 
                вроде Impala, Presto, Spark, и колоночными базами данных с корректной поддержкой<br> 
                первичных ключей, точечных обновлений и удалений, как InfluxDB.<br><br>
                В силу схожести архитектур, ClickHouse, Druid и Pinot имеют примерно одинаковый<br> 
                “предел оптимизации”. Но в своем текущем состоянии, <b>все три системы еще<br> 
                незрелы</b> и очень далеки от этого лимита. Существенных улучшений в<br> 
                производительности данных систем (применительно к специфическим сценариям<br> 
                использования) можно достичь несколькими человеко-месяцами работы опытных<br> 
                инженеров. 
                </p>
               <ul>
                <span style="background-color:yellow;">Я бы не рекомендовал вам сравнивать производительность данных систем<br> 
                между собой - выберите для себя ту, чей исходный код вы способны понять и<br> 
                модифицировать, или ту, в которую вы хотите инвестировать свои ресурсы.</span>
              </ul>
              <p>Из этих трех систем, ClickHouse стоит немного в стороне от Druid и Pinot - в то время<br> 
                как Druid и Pinot практически идентичны, и их можно считать двумя независимо<br> 
                разрабатываемыми реализациями одной и той же системы.<br><br>
                ClickHouse больше напоминает “традиционные” базы данных вроде PostgreSQL.<br> 
                ClickHouse можно установить на один узел. При малых масштабах (менее 1 TB<br> 
                памяти, менее 100 ядер CPU), ClickHouse выглядит гораздо более интересным<br> 
                вариантом, чем Druid или Pinot - если вам все еще хочется их сравнивать - в силу того,<br> 
                что ClickHouse проще и имеет меньше движущихся частей и сервисов. Я бы даже<br> 
                сказал, что на таком масштабе он скорее становится конкурентом для InfluxDB или<br> 
                Prometheus, а не для Druid или Pinot.<br><br>
                Druid и Pinot больше напоминают другие системы Big Data из экосистемы Hadoop. Они<br> 
                сохраняют свои “самоуправляемые” свойства даже на очень больших масштабах<br> 
                (более 500 узлов), в то время как ClickHouse потребует для этого достаточно много<br> 
                работы профессиональных SRE. Кроме того, Druid и Pinot занимают выигрышную<br> 
                позицию в плане оптимизации инфраструктурной стоимости больших кластеров, и<br> 
                лучше подходят для облачных окружений, чем ClickHouse.<br><br>
                Единственным долгосрочным различием между Druid и Pinot является то, что Pinot<br> 
                зависит от фреймворка Helix и будет продолжать зависеть от ZooKeeper, в то время<br> 
                как Druid может уйти от зависимости от ZooKeeper. С другой стороны, установка Druid<br> 
                продолжит зависеть от наличия какой-либо SQL-базы данных. На данный момент,<br> 
                Pinot оптимизирован лучше, чем Druid.</p>
                <ul>
                  <span style="background-color:yellow;">Если вы уже сталкивались с необходимостью сравнения этих систем и сделали<br> 
                    свой выбор, то приходите на одну из наших конференций и расскажите о своем<br> 
                    кейсе: о том какие именно были задачи и какие грабли (а наверняка они были) вы<br> 
                    встретили. Хотя, конечно, базы данных далеко не единственная тема.<br>
                    Ближайший по окончанию срока подачи заявок (до 9 апреля) фестиваль <a href="/">РИТ++<br></a> 
                    включает направления: <a href="/">фронтенд, бэкенд, эксплуатацию и управление.</a><br> 
                    Участникам обычно интереснее всего узнать о конкретных примерах, но и<br> 
                    выступления и в виде обзоров и исследований тоже возможны – главное, чтобы<br> тема была интересна лично вам.</span>
                </ul>








          </p>

           
      




        

      
  
  </p>

</div>
</body>
  
  
    
    
    
  </html>
      
  


